{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b9c3684f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torch import nn, optim\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torchsummary import summary\n",
    "import seaborn as sns\n",
    "from copy import deepcopy\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from scipy.interpolate import interp1d\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from torch import FloatTensor, tensor\n",
    "from torch.cuda import FloatTensor as GPUFloatTensor\n",
    "from torch.utils.data import Dataset, random_split\n",
    "\n",
    "# Req for package\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "from SkinLearning.NN.Helpers import train, test, DEVICE, getParameterLoss, setSeed\n",
    "from SkinLearning.NN.Models import MultiTemporal\n",
    "from SkinLearning.Utils.Dataset import getDataset, getSplit\n",
    "from SkinLearning.Utils.Plotting import plotParameterBars\n",
    "\n",
    "\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "59d0e80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Filters the signals based on the gradient of each phase\n",
    "\"\"\"\n",
    "def filterData(signalFolder=\"D:/SamplingResults2\", sampleFile=\"../Data/newSamples.pkl\", steps=128):\n",
    "    filtered = []\n",
    "    samples = []\n",
    "    runs = []\n",
    "    \n",
    "    f = open(f\"{sampleFile}\", \"rb\")\n",
    "    samples = pickle.load(f).astype(np.float32)\n",
    "    f.close()\n",
    "\n",
    "    for i, run in enumerate(tqdm(os.listdir(f\"{signalFolder}/\"))):  \n",
    "        inp = []\n",
    "        fail = False\n",
    "\n",
    "        #if i == 2000:\n",
    "           # break\n",
    "            \n",
    "        files = os.listdir(f\"{signalFolder}/{run}/\")\n",
    "\n",
    "        if files != ['Disp1.csv', 'Disp2.csv']:\n",
    "            continue\n",
    "\n",
    "        for file in files:\n",
    "            a = pd.read_csv(f\"{signalFolder}/{run}/{file}\")\n",
    "            a.rename(columns = {'0':'x', '0.1': 'y'}, inplace=True)\n",
    "\n",
    "            if a['x'].max() != 7.0:\n",
    "                fail = True\n",
    "                break\n",
    "            \n",
    "            # Interpolate curve for consistent x values\n",
    "            xNew = np.linspace(0, 7, num=steps, endpoint=True)\n",
    "            interped = interp1d(a['x'], a['y'], kind='cubic', fill_value=\"extrapolate\")(xNew)\n",
    "            interped[0] = 0.0\n",
    "            \n",
    "            if file == \"Disp1.csv\" and max(interped) > 1:\n",
    "                print(\"Found\")\n",
    "                fail = True\n",
    "                break\n",
    "            \n",
    "            if file == \"Disp2.csv\" and max(interped) > 2:\n",
    "                print(\"Found\")\n",
    "                fail = True\n",
    "                break\n",
    "                \n",
    "            # Check no sudden increases/decreases in gradient\n",
    "            max_def = 0 # x when displacement is first highest\n",
    "            max_def_final = 0\n",
    "            min_def = 0 # x when skin fully rebounds\n",
    "            step_second = 1/(7/steps) # Number of steps in each second\n",
    "            \n",
    "            der = 0\n",
    "            for i in range(len(interped)):\n",
    "                # Check x where max displacement occurs\n",
    "                if interped[i] > max(interped)*0.99 and max_def == 0:\n",
    "                    max_def = i/step_second\n",
    "                \n",
    "                if max_def != 0 and interped[i] == max(interped):\n",
    "                    max_def_final = i/step_second\n",
    "                \n",
    "                if max_def != 0 and interped[i] == min(interped[int(max_def_final):]):\n",
    "                    min_def = i/step_second\n",
    "   \n",
    "            # Cannot be within 10% of the max before 1\n",
    "            # Cannot reach rebound completely before 5.2 seconds\n",
    "            if min_def-max_def_final < 0.5 or max_def < 1:\n",
    "                fail = True\n",
    "                break\n",
    "\n",
    "            a = interped.astype(np.float32)\n",
    "            inp.append(a)\n",
    "\n",
    "        if not fail:\n",
    "            runs.append(run)\n",
    "            \n",
    "    runs = [int(run) for run in runs]\n",
    "    \n",
    "    return runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aeb1bda0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 65536/65536 [05:17<00:00, 206.43it/s]\n"
     ]
    }
   ],
   "source": [
    "runs = filterData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1063fd6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../Data/filtered.pkl\", \"rb\") as f:\n",
    "    old_runs = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0d4524c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2241 2241\n"
     ]
    }
   ],
   "source": [
    "print(len(runs), len(old_runs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b60ff701",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SkinDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        scaler,\n",
    "        signal_folder=\"D:/SamplingResults2\",\n",
    "        sample_file=\"../Data/newSamples.pkl\",\n",
    "        runs=range(65535),\n",
    "        steps=128\n",
    "        ):\n",
    "        # Load both disp1 and disp2 from each folder\n",
    "        # Folders ordered according to index of sample\n",
    "        self.input = []\n",
    "        self.output = []\n",
    "        \n",
    "        with open(f\"{sample_file}\", \"rb\") as f:\n",
    "             samples = pickle.load(f)\n",
    "        \n",
    "        for run in tqdm(runs):\n",
    "            inp = []\n",
    "            fail = False\n",
    "            \n",
    "            files = os.listdir(f\"{signal_folder}/{run}/\")\n",
    "            \n",
    "            if files != ['Disp1.csv', 'Disp2.csv']:\n",
    "                continue\n",
    "            \n",
    "            for file in files:\n",
    "                a = pd.read_csv(f\"{signal_folder}/{run}/{file}\")\n",
    "                a.rename(columns = {'0':'x', '0.1': 'y'}, inplace = True)\n",
    "                \n",
    "                # Skip if unconverged\n",
    "                if a['x'].max() != 7.0:\n",
    "                    fail = True\n",
    "                    break\n",
    "\n",
    "                # Interpolate curve for consistent x values\n",
    "                xNew = np.linspace(0, 7, num=steps, endpoint=False)\n",
    "                interped = interp1d(a['x'], a['y'], kind='cubic', fill_value=\"extrapolate\")(xNew)        \n",
    "                \n",
    "                inp.append(interped.astype(\"float32\"))\n",
    "            \n",
    "            if not fail:\n",
    "                if len(inp) != 2:\n",
    "                    raise Exception(\"sdf\")\n",
    "\n",
    "                self.input.append(inp)\n",
    "                self.output.append(samples[int(run)])\n",
    "        \n",
    "        # Normalise output variables\n",
    "        self.output = scaler.fit_transform(self.output)\n",
    "        \n",
    "        self.output = tensor(self.output).type(\n",
    "            FloatTensor if DEVICE == 'cpu' else GPUFloatTensor\n",
    "        )\n",
    "        self.input = tensor(np.array(self.input)).type(\n",
    "            FloatTensor if DEVICE == 'cpu' else GPUFloatTensor\n",
    "        )\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.output)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        sample = {\"input\": self.input[idx], \"output\": self.output[idx]}\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "556399ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Creates the data set from filtered samples\n",
    "    Returns the dataset and the scaler\n",
    "\"\"\"\n",
    "def getDataset(**kwargs):\n",
    "    # Get filtered data\n",
    "    if \"Data\" in os.listdir():\n",
    "        filtered_file = \"Data/filtered.pkl\"\n",
    "        kwargs['sample_file'] = \"Data/newSamples.pkl\"\n",
    "        kwargs['signal_folder'] = \"../SamplingResults2/\"\n",
    "    else:\n",
    "        filtered_file = \"../Data/filtered.pkl\"\n",
    "\n",
    "    if not 'runs' in kwargs.keys():\n",
    "        with open(filtered_file, \"rb\") as f:\n",
    "            runs = pickle.load(f)\n",
    "\n",
    "        kwargs['runs'] = runs\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    dataset = SkinDataset(scaler=scaler, **kwargs)\n",
    "\n",
    "    return dataset, scaler\n",
    "\n",
    "\"\"\"\n",
    "    Creates a train/test split from the given data\n",
    "    Returns train and test data loaders\n",
    "\"\"\"\n",
    "def getSplit(dataset, p1=0.8, batch_size=32):\n",
    "    train_n = int(p1 * len(dataset))\n",
    "    test_n = len(dataset) - train_n\n",
    "    train_set, test_set = random_split(dataset, [train_n, test_n])\n",
    "\n",
    "    return DataLoader(train_set, batch_size=batch_size, shuffle=True), \\\n",
    "        DataLoader(test_set, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8a5c9124",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 2241/2241 [00:10<00:00, 212.19it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset, scaler = getDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cf53dbf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, test_loader = getSplit(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "40caf3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = MultiTemporal(out=\"f_output\", single_fc=False, temporal_type=\"LSTM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "83eeaacb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 56/56 [00:01<00:00, 40.43batch/s]\n",
      "100%|██████████████████████████████| 56/56 [00:01<00:00, 41.66batch/s, counter=0, epoch=1, lastLoss=1.84, valLoss=0.21]\n",
      "100%|████████████████████████████| 56/56 [00:01<00:00, 42.18batch/s, counter=0, epoch=2, lastLoss=0.186, valLoss=0.191]\n",
      "100%|████████████████████████████| 56/56 [00:01<00:00, 42.12batch/s, counter=0, epoch=3, lastLoss=0.188, valLoss=0.186]\n",
      "100%|████████████████████████████| 56/56 [00:01<00:00, 41.82batch/s, counter=1, epoch=4, lastLoss=0.188, valLoss=0.187]\n",
      "100%|████████████████████████████| 56/56 [00:01<00:00, 41.93batch/s, counter=2, epoch=5, lastLoss=0.187, valLoss=0.194]\n",
      "100%|█████████████████████████████| 56/56 [00:01<00:00, 41.61batch/s, counter=3, epoch=6, lastLoss=0.189, valLoss=0.19]\n",
      "100%|████████████████████████████| 56/56 [00:01<00:00, 41.70batch/s, counter=4, epoch=7, lastLoss=0.187, valLoss=0.192]\n",
      "100%|████████████████████████████| 56/56 [00:01<00:00, 41.53batch/s, counter=5, epoch=8, lastLoss=0.188, valLoss=0.191]\n",
      "100%|████████████████████████████| 56/56 [00:01<00:00, 41.96batch/s, counter=6, epoch=9, lastLoss=0.187, valLoss=0.225]\n",
      "100%|███████████████████████████| 56/56 [00:01<00:00, 41.73batch/s, counter=7, epoch=10, lastLoss=0.188, valLoss=0.198]\n",
      "100%|████████████████████████████| 56/56 [00:01<00:00, 40.63batch/s, counter=8, epoch=11, lastLoss=0.188, valLoss=0.19]\n",
      "100%|███████████████████████████| 56/56 [00:01<00:00, 41.19batch/s, counter=0, epoch=12, lastLoss=0.187, valLoss=0.185]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [49]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m train_loss, val_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlstm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1500\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_loader\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Documents\\MastersDiss\\Notebooks\\..\\SkinLearning\\NN\\Helpers.py:126\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(train_loader, net, LR, epochs, val_loader, early_stopping, patience, optimizer, plot, cluster)\u001b[0m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, data \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(val_loader):\n\u001b[0;32m    124\u001b[0m     inp, out \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(DEVICE), data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(DEVICE)\n\u001b[1;32m--> 126\u001b[0m     predicted \u001b[38;5;241m=\u001b[39m \u001b[43mnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43minp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    127\u001b[0m     cost \u001b[38;5;241m=\u001b[39m criterion(out, predicted)\n\u001b[0;32m    128\u001b[0m     val_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m cost\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\Documents\\MastersDiss\\Notebooks\\..\\SkinLearning\\NN\\Models.py:101\u001b[0m, in \u001b[0;36mMultiTemporal.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     98\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     99\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcnn(x)\n\u001b[1;32m--> 101\u001b[0m o, (h, c) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mout \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mf_hidden\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    104\u001b[0m     x \u001b[38;5;241m=\u001b[39m h[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mreshape(batch_size, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:774\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m    772\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_forward_args(\u001b[38;5;28minput\u001b[39m, hx, batch_sizes)\n\u001b[0;32m    773\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_sizes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 774\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    775\u001b[0m \u001b[43m                      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbidirectional\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_first\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    776\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    777\u001b[0m     result \u001b[38;5;241m=\u001b[39m _VF\u001b[38;5;241m.\u001b[39mlstm(\u001b[38;5;28minput\u001b[39m, batch_sizes, hx, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_weights, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias,\n\u001b[0;32m    778\u001b[0m                       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbidirectional)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_loss, val_loss = train(train_loader, lstm, early_stopping=True, epochs=1500, val_loader=test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b6830e38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2241"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
