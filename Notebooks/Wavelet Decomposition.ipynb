{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "859219b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from torch import tensor\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import random\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "#from numba import jit\n",
    "import pickle\n",
    "from scipy.interpolate import interp1d\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torch\n",
    "from torchsummary import summary\n",
    "import seaborn as sns\n",
    "import sys\n",
    "import torch.nn.functional as F\n",
    "from torch.cuda import FloatTensor\n",
    "# Req for package\n",
    "sys.path.append(\"../\")\n",
    "from SkinLearning.Utils.NN import train, test, DEVICE\n",
    "import pywt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "1f18dd8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 123\n",
    "random.seed(seed)\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd97be2",
   "metadata": {},
   "source": [
    "# Wavelet decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "718ebd1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pywt\n",
    "import numpy as np\n",
    "\n",
    "def getCoefficients(samples, wavelet='db4', level=2):\n",
    "    \"\"\"\n",
    "    Performs wavelet packet decomposition on an array of samples and returns the coefficients.\n",
    "    \n",
    "    Args:\n",
    "        samples (ndarray): An array of shape (n_samples, 2, signal_length), where each sample\n",
    "            contains two 1D signals of length signal_length.\n",
    "        wavelet (str): The name of the wavelet to use for the wavelet packet decomposition.\n",
    "            Default is 'db1'.\n",
    "        level (int): The level of decomposition to use for the wavelet packet decomposition.\n",
    "            Default is 2.\n",
    "    \n",
    "    Returns:\n",
    "        ndarray: An array of shape (n_samples, 2, n_coefficients), where n_coefficients is the\n",
    "            total number of coefficients produced by the wavelet packet decomposition.\n",
    "    \"\"\"\n",
    "    n_samples, n_channels, signal_length = samples.shape\n",
    "    #n_coefficients = pywt.WaveletPacket(data=None, wavelet=wavelet, mode='symmetric', maxlevel=level)\n",
    "    #coefficients = np.zeros((n_samples, n_channels, n_coefficients))\n",
    "    coefficients = []\n",
    "    \n",
    "    for i in range(n_samples):\n",
    "        sample = []\n",
    "        for j in range(n_channels):\n",
    "            wp = pywt.WaveletPacket(data=samples[i][j], wavelet=wavelet, mode='periodic', maxlevel=level)\n",
    "            coeffs = np.array([node.data for node in wp.get_level(level, 'freq')])\n",
    "            sample.append(coefficients)\n",
    "        coefficients.append(np.array(sample))\n",
    "    return np.array(coefficients)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "470a9734",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCoefficients(samples, level=1):\n",
    "    \"\"\"\n",
    "    Computes the wavelet packet coefficients of each curve in every sample independently.\n",
    "    \n",
    "    Parameters:\n",
    "        samples (numpy.ndarray): Input array of shape (n_samples, 2, 128).\n",
    "        level (int): The level of decomposition to use.\n",
    "        \n",
    "    Returns:\n",
    "        numpy.ndarray: An array of shape (n_samples, 2, n) containing the wavelet packet coefficients\n",
    "                       for each curve in every sample independently.\n",
    "    \"\"\"\n",
    "    n_samples = len(samples)\n",
    "    n_coefficients = 2**level\n",
    "    output = []\n",
    "\n",
    "    for i in range(n_samples):\n",
    "        sample = []\n",
    "        for j in range(2):\n",
    "            wp = pywt.WaveletPacket(curves[0][0], 'db4', 'symmetric', maxlevel=1)\n",
    "            wp_coeffs = [node.data for node in wp.get_level(1, 'freq')]\n",
    "\n",
    "            num_coeffs = len(wp_coeffs)\n",
    "            low_freq_coeffs = np.concatenate(wp_coeffs[:num_coeffs // 2])\n",
    "            high_freq_coeffs = np.concatenate(wp_coeffs[num_coeffs // 2:])\n",
    "            ordered_coeffs = np.concatenate([low_freq_coeffs, high_freq_coeffs])\n",
    "            sample.append(np.array(ordered_coeffs))\n",
    "            \n",
    "        print(np.array(sample).shape)\n",
    "        output.append(np.array(sample))\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "06c1dafa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 2, 128)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "curves = np.array([dataset[i]['input'].cpu().numpy() for i in range(3)])\n",
    "curves.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "34e096e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n"
     ]
    }
   ],
   "source": [
    "coeffs = getCoefficients(curves, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "bfea70d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "23eb7c39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "134"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ordered_coeffs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8499aa36",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "00211a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder name will correspond to index of sample\n",
    "class SkinDataset(Dataset):\n",
    "    def __init__(self, scaler, signalFolder=\"D:/SamplingResults2\", sampleFile=\"../Data/newSamples.pkl\", runs=range(65535), steps=128):\n",
    "        # Load both disp1 and disp2 from each folder\n",
    "        # Folders ordered according to index of sample\n",
    "        # Use the corresponding sample as y -> append probe?\n",
    "        self.input = []\n",
    "        self.output = []\n",
    "        \n",
    "        with open(f\"{sampleFile}\", \"rb\") as f:\n",
    "             samples = pickle.load(f)\n",
    "        \n",
    "        self.min = np.min(samples[runs])\n",
    "        self.max = np.max(samples[runs])\n",
    "        \n",
    "        \n",
    "        for run in tqdm(runs):\n",
    "            inp = []\n",
    "            fail = False\n",
    "            \n",
    "            files = os.listdir(f\"{signalFolder}/{run}/\")\n",
    "            \n",
    "            if files != ['Disp1.csv', 'Disp2.csv']:\n",
    "                continue\n",
    "            \n",
    "            for file in files:\n",
    "                a = pd.read_csv(f\"{signalFolder}/{run}/{file}\")\n",
    "                a.rename(columns = {'0':'x', '0.1': 'y'}, inplace = True)\n",
    "                \n",
    "                # Skip if unconverged\n",
    "                if a['x'].max() != 7.0:\n",
    "                    fail = True\n",
    "                    break\n",
    "\n",
    "                # Interpolate curve for consistent x values\n",
    "                xNew = np.linspace(0, 7, num=steps, endpoint=False)\n",
    "                interped = interp1d(a['x'], a['y'], kind='cubic', fill_value=\"extrapolate\")(xNew)\n",
    "                    \n",
    "                \n",
    "                inp.append(interped.astype(\"float32\"))\n",
    "            \n",
    "            if not fail:\n",
    "                if len(inp) != 2:\n",
    "                    raise Exception(\"sdf\")\n",
    "\n",
    "                self.input.append(inp)\n",
    "                self.output.append(samples[int(run)])\n",
    "        \n",
    "        scaler.fit(self.output)\n",
    "        self.output = scaler.fit_transform(self.output)\n",
    "        self.output = tensor(self.output).type(FloatTensor)\n",
    "        self.input = tensor(np.array(getCoefficients(self.input))).type(FloatTensor)\n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.output)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        sample = {\"input\": self.input[idx], \"output\": self.output[idx]}\n",
    "        return sample\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "974eb1eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Creates the data set from filtered samples\n",
    "    Returns the dataset and the scaler\n",
    "\"\"\"\n",
    "def getDataset(**kwargs):\n",
    "    # Get filtered data\n",
    "    if not 'runs' in kwargs.keys():\n",
    "        with open(\"../Data/filtered.pkl\", \"rb\") as f:\n",
    "            runs = pickle.load(f)\n",
    "\n",
    "        kwargs['runs'] = runs\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    dataset = SkinDataset(scaler=scaler, **kwargs)\n",
    "\n",
    "    return dataset, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "3bf2c52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Creates a train/test split from the given data\n",
    "    Returns train and test data loaders\n",
    "\"\"\"\n",
    "def getSplit(dataset, p1=0.8):\n",
    "    train_n = int(p1 * len(dataset))\n",
    "    test_n = len(dataset) - train_n\n",
    "    train_set, test_set = random_split(dataset, [train_n, test_n])\n",
    "\n",
    "    return DataLoader(train_set, batch_size=32, shuffle=True), \\\n",
    "        DataLoader(test_set, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "b9a8c0cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 2241/2241 [00:09<00:00, 242.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n",
      "(2, 134)\n"
     ]
    }
   ],
   "source": [
    "dataset, scaler = getDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "98edea7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, test_loader = getSplit(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b45846",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "ee77f865",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RNN, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(2, 128, kernel_size=5, padding=1, bias=False)\n",
    "        self.pool1 = nn.MaxPool1d(kernel_size=5, stride=2)\n",
    "        self.bn1 = nn.BatchNorm1d(128)\n",
    "        \n",
    "        self.conv2 = nn.Conv1d(128, 256, kernel_size=3, padding=1, bias=False)\n",
    "        self.pool2 = nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "        self.bn2 = nn.BatchNorm1d(256)\n",
    "        \n",
    "        \n",
    "        self.rnn = nn.RNN(32, 256, batch_first=True)\n",
    "        self.fc1 = nn.Linear(65536, 1024)\n",
    "        self.d1 = nn.Dropout(0.5)\n",
    "        \n",
    "        self.fc2 = nn.Linear(1024 , 512)\n",
    "        self.d2 = nn.Dropout(0.5)\n",
    "        \n",
    "        self.fc3 = nn.Linear(512, 128)\n",
    "        self.d3 = nn.Dropout(0.5)\n",
    "        \n",
    "        self.fc4 = nn.Linear(128, 6)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.shape[0]\n",
    "        x = self.pool1(torch.relu(self.bn1(self.conv1(x))))\n",
    "        x = self.pool2(torch.relu(self.bn2(self.conv2(x))))\n",
    "        \n",
    "        h0 = torch.zeros(1, batch_size, 256).to(x.device)\n",
    "        x, _ = self.rnn(x, h0)\n",
    "        x = x.reshape(batch_size, -1)\n",
    "        x = self.d1(torch.relu(self.fc1(x)))\n",
    "        \n",
    "        x = self.d2(torch.relu(self.fc2(x)))\n",
    "        \n",
    "        x = self.d3(torch.relu(self.fc3(x)))\n",
    "        x = self.fc4(x)\n",
    "        \n",
    "        x = x.view(batch_size, 6)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "3b1fd2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Up samples to 256 from 128\n",
    "class UpMinus(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(UpMinus, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(2, 128, kernel_size=5, padding=1, bias=False)\n",
    "        self.pool1 = nn.MaxPool1d(kernel_size=5, stride=2)\n",
    "        self.bn1 = nn.BatchNorm1d(128)\n",
    "        self.d1 = nn.Dropout(0.2)\n",
    "        \n",
    "        self.conv2 = nn.Conv1d(128, 256, kernel_size=3, padding=1, bias=False)\n",
    "        self.pool2 = nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "        self.bn2 = nn.BatchNorm1d(256)\n",
    "        self.d2 = nn.Dropout(0.2)\n",
    "        \n",
    "        self.fc1 = nn.Linear(8192, 512)\n",
    "        self.d5 = nn.Dropout(0.5)\n",
    "        \n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.d6 = nn.Dropout(0.5)\n",
    "        \n",
    "        self.fc3 = nn.Linear(256, 64)\n",
    "        self.d7 = nn.Dropout(0.5)\n",
    "        \n",
    "        self.fc4 = nn.Linear(64, 6)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.shape[0]\n",
    "        x = self.pool1(torch.relu(self.bn1(self.d1(self.conv1(x)))))\n",
    "        x = self.pool2(torch.relu(self.bn2(self.d2(self.conv2(x)))))\n",
    "        \n",
    "        \n",
    "        x = x.view(batch_size, -1)\n",
    "        \n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.d5(x)\n",
    "        \n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.d6(x)\n",
    "        \n",
    "        x = torch.relu(self.fc3(x))\n",
    "        x = self.d7(x)\n",
    "        \n",
    "        \n",
    "        x = self.fc4(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "6c0c00be",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(2, 128, kernel_size=5, padding=1, bias=False)\n",
    "        self.pool1 = nn.MaxPool1d(kernel_size=5, stride=2)\n",
    "        self.bn1 = nn.BatchNorm1d(128)\n",
    "        \n",
    "        self.conv2 = nn.Conv1d(128, 256, kernel_size=3, padding=1, bias=False)\n",
    "        self.pool2 = nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "        self.bn2 = nn.BatchNorm1d(256)\n",
    "        \n",
    "        self.conv3 = nn.Conv1d(256, 512, kernel_size=3, padding=1, bias=False)\n",
    "        self.pool3 = nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "        self.bn3 = nn.BatchNorm1d(512)\n",
    "        \n",
    "        # Define the LSTM layer\n",
    "        self.lstm = nn.LSTM(input_size=16,\n",
    "                            hidden_size=256,\n",
    "                            num_layers=1,\n",
    "                            batch_first=True)\n",
    "        \n",
    "        \n",
    "        self.fc1 = nn.Linear(256, 128)\n",
    "        self.d1 = nn.Dropout(0.5)\n",
    "        \n",
    "        self.fc2 = nn.Linear(128 , 64)\n",
    "        self.d2 = nn.Dropout(0.5)\n",
    "        \n",
    "        self.fc3 = nn.Linear(64, 32)\n",
    "        self.d3 = nn.Dropout(0.5)\n",
    "        \n",
    "        self.fc4 = nn.Linear(32, 6)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        batch_size = x.shape[0]\n",
    "        \n",
    "        x = self.pool1(torch.relu(self.bn1(self.conv1(x))))\n",
    "        x = self.pool2(torch.relu(self.bn2(self.conv2(x))))\n",
    "        x = self.pool3(torch.relu(self.bn3(self.conv3(x))))\n",
    "        \n",
    "        # Pass the reshaped input through the LSTM layer\n",
    "        lstm_output, (h_n, c_n) = self.lstm(x)\n",
    "        \n",
    "        # Use the final hidden state of the LSTM as input to the final fully connected layer\n",
    "        x = self.d1(torch.relu(self.fc1(h_n[-1, :, :])))\n",
    "        \n",
    "        x = self.d2(torch.relu(self.fc2(x)))\n",
    "        x = self.d3(torch.relu(self.fc3(x)))\n",
    "        \n",
    "        x = self.fc4(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d37af1f",
   "metadata": {},
   "source": [
    "# Test on all samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "dbbe21ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "upMinus = UpMinus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "206f1d0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/550: 100%|██████████████████████████████████████████████████████████████████| 56/56 [00:03<00:00, 17.78batch/s]\n",
      "Epoch 2/550: 100%|███████████████████████████████████| 56/56 [00:03<00:00, 18.22batch/s, lastLoss=0.272, valLoss=0.265]\n",
      "Epoch 3/550: 100%|███████████████████████████████████| 56/56 [00:03<00:00, 17.71batch/s, lastLoss=0.244, valLoss=0.254]\n",
      "Epoch 4/550: 100%|████████████████████████████████████| 56/56 [00:03<00:00, 18.01batch/s, lastLoss=0.234, valLoss=0.24]\n",
      "Epoch 5/550: 100%|███████████████████████████████████| 56/56 [00:03<00:00, 17.75batch/s, lastLoss=0.229, valLoss=0.228]\n",
      "Epoch 6/550: 100%|███████████████████████████████████| 56/56 [00:03<00:00, 17.82batch/s, lastLoss=0.222, valLoss=0.232]\n",
      "Epoch 7/550: 100%|███████████████████████████████████| 56/56 [00:03<00:00, 18.01batch/s, lastLoss=0.221, valLoss=0.229]\n",
      "Epoch 8/550: 100%|███████████████████████████████████| 56/56 [00:04<00:00, 12.63batch/s, lastLoss=0.218, valLoss=0.226]\n",
      "Epoch 9/550: 100%|███████████████████████████████████| 56/56 [00:04<00:00, 13.68batch/s, lastLoss=0.214, valLoss=0.219]\n",
      "Epoch 10/550: 100%|██████████████████████████████████| 56/56 [00:04<00:00, 13.37batch/s, lastLoss=0.212, valLoss=0.222]\n",
      "Epoch 11/550: 100%|███████████████████████████████████| 56/56 [00:04<00:00, 13.66batch/s, lastLoss=0.21, valLoss=0.224]\n",
      "Epoch 12/550: 100%|██████████████████████████████████| 56/56 [00:04<00:00, 13.46batch/s, lastLoss=0.209, valLoss=0.214]\n",
      "Epoch 13/550: 100%|██████████████████████████████████| 56/56 [00:04<00:00, 13.85batch/s, lastLoss=0.207, valLoss=0.217]\n",
      "Epoch 14/550: 100%|██████████████████████████████████| 56/56 [00:04<00:00, 13.55batch/s, lastLoss=0.206, valLoss=0.211]\n",
      "Epoch 15/550: 100%|██████████████████████████████████| 56/56 [00:04<00:00, 13.84batch/s, lastLoss=0.205, valLoss=0.225]\n",
      "Epoch 16/550: 100%|███████████████████████████████████| 56/56 [00:04<00:00, 13.15batch/s, lastLoss=0.203, valLoss=0.21]\n",
      "Epoch 17/550: 100%|██████████████████████████████████| 56/56 [00:03<00:00, 14.22batch/s, lastLoss=0.203, valLoss=0.214]\n",
      "Epoch 18/550: 100%|███████████████████████████████████| 56/56 [00:04<00:00, 13.21batch/s, lastLoss=0.201, valLoss=0.21]\n",
      "Epoch 19/550: 100%|██████████████████████████████████| 56/56 [00:04<00:00, 13.02batch/s, lastLoss=0.202, valLoss=0.217]\n",
      "Epoch 20/550: 100%|████████████████████████████████████| 56/56 [00:04<00:00, 13.66batch/s, lastLoss=0.2, valLoss=0.212]\n",
      "Epoch 21/550: 100%|█████████████████████████████████████| 56/56 [00:04<00:00, 13.36batch/s, lastLoss=0.2, valLoss=0.21]\n",
      "Epoch 22/550: 100%|██████████████████████████████████| 56/56 [00:04<00:00, 13.28batch/s, lastLoss=0.198, valLoss=0.208]\n",
      "Epoch 23/550: 100%|██████████████████████████████████| 56/56 [00:05<00:00, 10.11batch/s, lastLoss=0.198, valLoss=0.214]\n",
      "Epoch 24/550: 100%|██████████████████████████████████| 56/56 [00:04<00:00, 11.76batch/s, lastLoss=0.199, valLoss=0.213]\n",
      "Epoch 25/550: 100%|██████████████████████████████████| 56/56 [00:05<00:00, 10.82batch/s, lastLoss=0.197, valLoss=0.213]\n",
      "Epoch 26/550: 100%|██████████████████████████████████| 56/56 [00:05<00:00, 10.92batch/s, lastLoss=0.197, valLoss=0.217]\n",
      "Epoch 27/550: 100%|██████████████████████████████████| 56/56 [00:04<00:00, 11.26batch/s, lastLoss=0.197, valLoss=0.212]\n",
      "Epoch 28/550: 100%|██████████████████████████████████| 56/56 [00:03<00:00, 14.57batch/s, lastLoss=0.197, valLoss=0.211]\n",
      "Epoch 29/550: 100%|██████████████████████████████████| 56/56 [00:03<00:00, 14.10batch/s, lastLoss=0.195, valLoss=0.214]\n",
      "Epoch 30/550: 100%|██████████████████████████████████| 56/56 [00:03<00:00, 14.13batch/s, lastLoss=0.194, valLoss=0.214]\n",
      "Epoch 31/550: 100%|██████████████████████████████████| 56/56 [00:04<00:00, 13.91batch/s, lastLoss=0.195, valLoss=0.203]\n",
      "Epoch 32/550: 100%|██████████████████████████████████| 56/56 [00:03<00:00, 14.38batch/s, lastLoss=0.195, valLoss=0.208]\n",
      "Epoch 33/550: 100%|██████████████████████████████████| 56/56 [00:03<00:00, 14.33batch/s, lastLoss=0.193, valLoss=0.206]\n",
      "Epoch 34/550: 100%|██████████████████████████████████| 56/56 [00:03<00:00, 14.11batch/s, lastLoss=0.195, valLoss=0.205]\n",
      "Epoch 35/550: 100%|██████████████████████████████████| 56/56 [00:04<00:00, 13.86batch/s, lastLoss=0.192, valLoss=0.199]\n",
      "Epoch 36/550: 100%|██████████████████████████████████| 56/56 [00:03<00:00, 14.33batch/s, lastLoss=0.193, valLoss=0.209]\n",
      "Epoch 37/550: 100%|██████████████████████████████████| 56/56 [00:04<00:00, 13.73batch/s, lastLoss=0.193, valLoss=0.197]\n",
      "Epoch 38/550: 100%|██████████████████████████████████| 56/56 [00:03<00:00, 14.24batch/s, lastLoss=0.193, valLoss=0.196]\n",
      "Epoch 39/550: 100%|██████████████████████████████████| 56/56 [00:04<00:00, 13.85batch/s, lastLoss=0.192, valLoss=0.209]\n",
      "Epoch 40/550: 100%|██████████████████████████████████| 56/56 [00:03<00:00, 14.63batch/s, lastLoss=0.193, valLoss=0.195]\n",
      "Epoch 41/550: 100%|██████████████████████████████████| 56/56 [00:04<00:00, 13.98batch/s, lastLoss=0.192, valLoss=0.201]\n",
      "Epoch 42/550: 100%|███████████████████████████████████| 56/56 [00:03<00:00, 14.30batch/s, lastLoss=0.193, valLoss=0.19]\n",
      "Epoch 43/550: 100%|██████████████████████████████████| 56/56 [00:03<00:00, 14.83batch/s, lastLoss=0.193, valLoss=0.191]\n",
      "Epoch 44/550: 100%|██████████████████████████████████| 56/56 [00:03<00:00, 14.27batch/s, lastLoss=0.191, valLoss=0.186]\n",
      "Epoch 45/550: 100%|███████████████████████████████████| 56/56 [00:04<00:00, 13.95batch/s, lastLoss=0.19, valLoss=0.176]\n",
      "Epoch 46/550: 100%|███████████████████████████████████| 56/56 [00:03<00:00, 14.05batch/s, lastLoss=0.19, valLoss=0.181]\n",
      "Epoch 47/550: 100%|███████████████████████████████████| 56/56 [00:03<00:00, 14.30batch/s, lastLoss=0.19, valLoss=0.179]\n",
      "Epoch 48/550: 100%|███████████████████████████████████| 56/56 [00:03<00:00, 14.35batch/s, lastLoss=0.19, valLoss=0.182]\n",
      "Epoch 49/550: 100%|████████████████████████████████████| 56/56 [00:04<00:00, 13.88batch/s, lastLoss=0.19, valLoss=0.19]\n",
      "Epoch 50/550: 100%|███████████████████████████████████| 56/56 [00:03<00:00, 14.31batch/s, lastLoss=0.19, valLoss=0.184]\n",
      "Epoch 51/550: 100%|███████████████████████████████████| 56/56 [00:04<00:00, 13.91batch/s, lastLoss=0.19, valLoss=0.185]\n",
      "Epoch 52/550: 100%|██████████████████████████████████| 56/56 [00:03<00:00, 14.06batch/s, lastLoss=0.189, valLoss=0.186]\n",
      "Epoch 53/550: 100%|███████████████████████████████████| 56/56 [00:03<00:00, 14.72batch/s, lastLoss=0.19, valLoss=0.187]\n",
      "Epoch 54/550: 100%|███████████████████████████████████| 56/56 [00:03<00:00, 14.78batch/s, lastLoss=0.19, valLoss=0.184]\n",
      "Epoch 55/550: 100%|███████████████████████████████████| 56/56 [00:03<00:00, 14.57batch/s, lastLoss=0.19, valLoss=0.184]\n",
      "Epoch 56/550: 100%|███████████████████████████████████| 56/56 [00:03<00:00, 14.61batch/s, lastLoss=0.19, valLoss=0.191]\n",
      "Epoch 57/550: 100%|██████████████████████████████████| 56/56 [00:03<00:00, 14.91batch/s, lastLoss=0.189, valLoss=0.179]\n",
      "Epoch 58/550: 100%|███████████████████████████████████| 56/56 [00:04<00:00, 12.87batch/s, lastLoss=0.19, valLoss=0.186]\n",
      "Epoch 59/550: 100%|██████████████████████████████████| 56/56 [00:04<00:00, 13.25batch/s, lastLoss=0.188, valLoss=0.184]\n",
      "Epoch 60/550: 100%|███████████████████████████████████| 56/56 [00:04<00:00, 12.86batch/s, lastLoss=0.19, valLoss=0.183]\n",
      "Epoch 61/550: 100%|██████████████████████████████████| 56/56 [00:04<00:00, 13.38batch/s, lastLoss=0.189, valLoss=0.179]\n",
      "Epoch 62/550: 100%|██████████████████████████████████| 56/56 [00:04<00:00, 13.48batch/s, lastLoss=0.189, valLoss=0.184]\n",
      "Epoch 63/550: 100%|██████████████████████████████████| 56/56 [00:04<00:00, 13.19batch/s, lastLoss=0.189, valLoss=0.182]\n",
      "Epoch 64/550: 100%|██████████████████████████████████| 56/56 [00:04<00:00, 12.28batch/s, lastLoss=0.189, valLoss=0.184]\n",
      "Epoch 65/550:  21%|███████▎                          | 12/56 [00:00<00:02, 16.06batch/s, lastLoss=0.188, valLoss=0.188]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [239]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m upMinus_losses, upMinus_val_losses, \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mupMinus\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mLR\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.0001\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m550\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Documents\\MastersDiss\\Notebooks\\..\\SkinLearning\\Utils\\NN.py:42\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(train_loader, net, LR, epochs, val_loader)\u001b[0m\n\u001b[0;32m     40\u001b[0m current_MSE \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m6\u001b[39m):\n\u001b[1;32m---> 42\u001b[0m     current_MSE\u001b[38;5;241m.\u001b[39mappend(\u001b[43mall_MSE\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredicted\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     43\u001b[0m parameter_loss\u001b[38;5;241m.\u001b[39mappend(current_MSE)\n\u001b[0;32m     44\u001b[0m processed \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "upMinus_losses, upMinus_val_losses, = train(train_loader, upMinus, val_loader=test_loader, LR=0.0001, epochs=550)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "531f9039",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = RNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a577e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/400: 100%|██████████████████████████████████████████████████████████████████| 56/56 [00:05<00:00, 10.81batch/s]\n",
      "Epoch 2/400: 100%|███████████████████████████████████| 56/56 [00:05<00:00, 10.93batch/s, lastLoss=0.251, valLoss=0.295]\n",
      "Epoch 3/400: 100%|███████████████████████████████████| 56/56 [00:05<00:00, 10.84batch/s, lastLoss=0.217, valLoss=0.213]\n",
      "Epoch 4/400: 100%|███████████████████████████████████| 56/56 [00:05<00:00, 10.94batch/s, lastLoss=0.211, valLoss=0.208]\n",
      "Epoch 5/400: 100%|███████████████████████████████████| 56/56 [00:05<00:00, 10.82batch/s, lastLoss=0.207, valLoss=0.189]\n",
      "Epoch 6/400: 100%|███████████████████████████████████| 56/56 [00:05<00:00, 10.85batch/s, lastLoss=0.209, valLoss=0.202]\n",
      "Epoch 7/400: 100%|███████████████████████████████████| 56/56 [00:05<00:00, 10.40batch/s, lastLoss=0.206, valLoss=0.191]\n",
      "Epoch 8/400: 100%|███████████████████████████████████| 56/56 [00:05<00:00,  9.90batch/s, lastLoss=0.206, valLoss=0.199]\n",
      "Epoch 9/400: 100%|███████████████████████████████████| 56/56 [00:05<00:00,  9.94batch/s, lastLoss=0.202, valLoss=0.191]\n",
      "Epoch 10/400: 100%|██████████████████████████████████| 56/56 [00:05<00:00,  9.78batch/s, lastLoss=0.203, valLoss=0.203]\n",
      "Epoch 11/400: 100%|██████████████████████████████████| 56/56 [00:05<00:00, 10.03batch/s, lastLoss=0.201, valLoss=0.187]\n",
      "Epoch 12/400: 100%|██████████████████████████████████| 56/56 [00:05<00:00, 10.09batch/s, lastLoss=0.202, valLoss=0.204]\n",
      "Epoch 13/400: 100%|██████████████████████████████████| 56/56 [00:05<00:00, 10.09batch/s, lastLoss=0.198, valLoss=0.192]\n",
      "Epoch 14/400: 100%|████████████████████████████████████| 56/56 [00:05<00:00,  9.85batch/s, lastLoss=0.199, valLoss=0.2]\n",
      "Epoch 15/400: 100%|████████████████████████████████████| 56/56 [00:05<00:00,  9.92batch/s, lastLoss=0.2, valLoss=0.195]\n",
      "Epoch 16/400: 100%|███████████████████████████████████| 56/56 [00:05<00:00,  9.68batch/s, lastLoss=0.197, valLoss=0.19]\n",
      "Epoch 17/400: 100%|██████████████████████████████████| 56/56 [00:05<00:00,  9.82batch/s, lastLoss=0.196, valLoss=0.205]\n",
      "Epoch 18/400: 100%|██████████████████████████████████| 56/56 [00:05<00:00,  9.86batch/s, lastLoss=0.197, valLoss=0.198]\n",
      "Epoch 19/400: 100%|██████████████████████████████████| 56/56 [00:05<00:00,  9.72batch/s, lastLoss=0.198, valLoss=0.208]\n",
      "Epoch 20/400: 100%|██████████████████████████████████| 56/56 [00:05<00:00,  9.91batch/s, lastLoss=0.195, valLoss=0.201]\n",
      "Epoch 21/400: 100%|██████████████████████████████████| 56/56 [00:05<00:00,  9.81batch/s, lastLoss=0.195, valLoss=0.197]\n",
      "Epoch 22/400: 100%|██████████████████████████████████| 56/56 [00:05<00:00,  9.91batch/s, lastLoss=0.195, valLoss=0.199]\n",
      "Epoch 23/400: 100%|██████████████████████████████████| 56/56 [00:05<00:00,  9.81batch/s, lastLoss=0.195, valLoss=0.192]\n",
      "Epoch 24/400: 100%|██████████████████████████████████| 56/56 [00:05<00:00,  9.85batch/s, lastLoss=0.194, valLoss=0.205]\n",
      "Epoch 25/400: 100%|██████████████████████████████████| 56/56 [00:05<00:00,  9.62batch/s, lastLoss=0.196, valLoss=0.204]\n",
      "Epoch 26/400: 100%|██████████████████████████████████| 56/56 [00:05<00:00,  9.67batch/s, lastLoss=0.194, valLoss=0.199]\n",
      "Epoch 27/400: 100%|██████████████████████████████████| 56/56 [00:05<00:00,  9.98batch/s, lastLoss=0.194, valLoss=0.199]\n",
      "Epoch 28/400: 100%|██████████████████████████████████| 56/56 [00:05<00:00,  9.61batch/s, lastLoss=0.195, valLoss=0.193]\n",
      "Epoch 29/400: 100%|██████████████████████████████████| 56/56 [00:05<00:00,  9.79batch/s, lastLoss=0.192, valLoss=0.199]\n",
      "Epoch 30/400: 100%|██████████████████████████████████| 56/56 [00:05<00:00,  9.74batch/s, lastLoss=0.193, valLoss=0.205]\n",
      "Epoch 31/400: 100%|██████████████████████████████████| 56/56 [00:05<00:00,  9.93batch/s, lastLoss=0.193, valLoss=0.201]\n",
      "Epoch 32/400: 100%|██████████████████████████████████| 56/56 [00:05<00:00,  9.75batch/s, lastLoss=0.192, valLoss=0.203]\n",
      "Epoch 33/400: 100%|██████████████████████████████████| 56/56 [00:05<00:00,  9.84batch/s, lastLoss=0.192, valLoss=0.193]\n",
      "Epoch 34/400: 100%|██████████████████████████████████| 56/56 [00:05<00:00,  9.83batch/s, lastLoss=0.192, valLoss=0.201]\n",
      "Epoch 35/400: 100%|██████████████████████████████████| 56/56 [00:05<00:00,  9.94batch/s, lastLoss=0.192, valLoss=0.215]\n",
      "Epoch 36/400: 100%|███████████████████████████████████| 56/56 [00:05<00:00,  9.73batch/s, lastLoss=0.192, valLoss=0.21]\n",
      "Epoch 37/400: 100%|██████████████████████████████████| 56/56 [00:05<00:00,  9.87batch/s, lastLoss=0.192, valLoss=0.208]\n",
      "Epoch 38/400: 100%|██████████████████████████████████| 56/56 [00:05<00:00, 10.32batch/s, lastLoss=0.192, valLoss=0.203]\n",
      "Epoch 39/400: 100%|██████████████████████████████████| 56/56 [00:05<00:00,  9.97batch/s, lastLoss=0.192, valLoss=0.202]\n",
      "Epoch 40/400: 100%|██████████████████████████████████| 56/56 [00:05<00:00, 10.23batch/s, lastLoss=0.192, valLoss=0.202]\n",
      "Epoch 41/400: 100%|██████████████████████████████████| 56/56 [00:05<00:00, 10.31batch/s, lastLoss=0.192, valLoss=0.202]\n",
      "Epoch 42/400: 100%|███████████████████████████████████| 56/56 [00:05<00:00, 10.21batch/s, lastLoss=0.19, valLoss=0.201]\n",
      "Epoch 43/400: 100%|██████████████████████████████████| 56/56 [00:05<00:00, 10.17batch/s, lastLoss=0.191, valLoss=0.204]\n",
      "Epoch 44/400: 100%|██████████████████████████████████| 56/56 [00:05<00:00, 10.19batch/s, lastLoss=0.191, valLoss=0.196]\n",
      "Epoch 45/400: 100%|██████████████████████████████████| 56/56 [00:05<00:00, 10.24batch/s, lastLoss=0.191, valLoss=0.198]\n",
      "Epoch 46/400: 100%|███████████████████████████████████| 56/56 [00:05<00:00, 10.02batch/s, lastLoss=0.19, valLoss=0.201]\n",
      "Epoch 47/400: 100%|███████████████████████████████████| 56/56 [00:05<00:00, 10.21batch/s, lastLoss=0.19, valLoss=0.203]\n",
      "Epoch 48/400: 100%|██████████████████████████████████| 56/56 [00:05<00:00, 10.16batch/s, lastLoss=0.191, valLoss=0.199]\n",
      "Epoch 49/400: 100%|██████████████████████████████████| 56/56 [00:05<00:00, 10.33batch/s, lastLoss=0.189, valLoss=0.199]\n",
      "Epoch 50/400: 100%|██████████████████████████████████| 56/56 [00:05<00:00, 10.33batch/s, lastLoss=0.191, valLoss=0.191]\n",
      "Epoch 51/400: 100%|███████████████████████████████████| 56/56 [00:05<00:00, 10.28batch/s, lastLoss=0.19, valLoss=0.186]\n",
      "Epoch 52/400: 100%|██████████████████████████████████| 56/56 [00:05<00:00, 10.14batch/s, lastLoss=0.191, valLoss=0.198]\n",
      "Epoch 53/400: 100%|███████████████████████████████████| 56/56 [00:05<00:00, 10.20batch/s, lastLoss=0.19, valLoss=0.196]\n",
      "Epoch 54/400: 100%|██████████████████████████████████| 56/56 [00:05<00:00, 10.27batch/s, lastLoss=0.191, valLoss=0.191]\n",
      "Epoch 55/400: 100%|█████████████████████████████████████| 56/56 [00:05<00:00, 10.12batch/s, lastLoss=0.19, valLoss=0.2]\n",
      "Epoch 56/400: 100%|███████████████████████████████████| 56/56 [00:05<00:00, 10.20batch/s, lastLoss=0.189, valLoss=0.19]\n",
      "Epoch 57/400: 100%|██████████████████████████████████| 56/56 [00:05<00:00, 10.19batch/s, lastLoss=0.189, valLoss=0.196]\n",
      "Epoch 58/400: 100%|███████████████████████████████████| 56/56 [00:05<00:00, 10.32batch/s, lastLoss=0.19, valLoss=0.193]\n",
      "Epoch 59/400: 100%|███████████████████████████████████| 56/56 [00:05<00:00, 10.18batch/s, lastLoss=0.19, valLoss=0.192]\n",
      "Epoch 60/400: 100%|██████████████████████████████████| 56/56 [00:05<00:00, 10.33batch/s, lastLoss=0.189, valLoss=0.194]\n",
      "Epoch 61/400: 100%|██████████████████████████████████| 56/56 [00:05<00:00, 10.22batch/s, lastLoss=0.189, valLoss=0.195]\n",
      "Epoch 62/400: 100%|██████████████████████████████████| 56/56 [00:05<00:00, 10.21batch/s, lastLoss=0.189, valLoss=0.203]\n",
      "Epoch 63/400: 100%|████████████████████████████████████| 56/56 [00:05<00:00, 10.19batch/s, lastLoss=0.189, valLoss=0.2]\n",
      "Epoch 64/400: 100%|███████████████████████████████████| 56/56 [00:05<00:00, 10.20batch/s, lastLoss=0.19, valLoss=0.191]\n",
      "Epoch 65/400: 100%|██████████████████████████████████| 56/56 [00:05<00:00, 10.26batch/s, lastLoss=0.189, valLoss=0.193]\n",
      "Epoch 66/400: 100%|██████████████████████████████████| 56/56 [00:05<00:00, 10.15batch/s, lastLoss=0.189, valLoss=0.192]\n",
      "Epoch 67/400: 100%|██████████████████████████████████| 56/56 [00:05<00:00, 10.15batch/s, lastLoss=0.189, valLoss=0.187]\n",
      "Epoch 68/400: 100%|███████████████████████████████████| 56/56 [00:05<00:00, 10.22batch/s, lastLoss=0.19, valLoss=0.189]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 69/400: 100%|███████████████████████████████████| 56/56 [00:05<00:00, 10.41batch/s, lastLoss=0.19, valLoss=0.189]\n",
      "Epoch 70/400: 100%|██████████████████████████████████| 56/56 [00:05<00:00, 10.44batch/s, lastLoss=0.189, valLoss=0.189]\n",
      "Epoch 71/400: 100%|██████████████████████████████████| 56/56 [00:05<00:00, 10.38batch/s, lastLoss=0.188, valLoss=0.183]\n",
      "Epoch 72/400: 100%|██████████████████████████████████| 56/56 [00:05<00:00,  9.91batch/s, lastLoss=0.189, valLoss=0.177]\n",
      "Epoch 73/400: 100%|██████████████████████████████████| 56/56 [00:05<00:00, 10.23batch/s, lastLoss=0.189, valLoss=0.186]\n",
      "Epoch 74/400: 100%|██████████████████████████████████| 56/56 [00:05<00:00, 10.30batch/s, lastLoss=0.189, valLoss=0.189]\n",
      "Epoch 75/400: 100%|██████████████████████████████████| 56/56 [00:05<00:00, 10.40batch/s, lastLoss=0.189, valLoss=0.187]\n",
      "Epoch 76/400: 100%|███████████████████████████████████| 56/56 [00:05<00:00, 10.41batch/s, lastLoss=0.189, valLoss=0.19]\n",
      "Epoch 77/400: 100%|███████████████████████████████████| 56/56 [00:05<00:00, 10.33batch/s, lastLoss=0.189, valLoss=0.19]\n",
      "Epoch 78/400: 100%|██████████████████████████████████| 56/56 [00:05<00:00,  9.65batch/s, lastLoss=0.189, valLoss=0.188]\n",
      "Epoch 79/400: 100%|██████████████████████████████████| 56/56 [00:05<00:00, 10.24batch/s, lastLoss=0.189, valLoss=0.189]\n",
      "Epoch 80/400: 100%|███████████████████████████████████| 56/56 [00:05<00:00, 10.27batch/s, lastLoss=0.188, valLoss=0.18]\n",
      "Epoch 81/400: 100%|██████████████████████████████████| 56/56 [00:05<00:00, 10.31batch/s, lastLoss=0.188, valLoss=0.186]\n",
      "Epoch 82/400: 100%|██████████████████████████████████| 56/56 [00:05<00:00, 10.21batch/s, lastLoss=0.188, valLoss=0.189]\n",
      "Epoch 83/400: 100%|██████████████████████████████████| 56/56 [00:05<00:00, 10.40batch/s, lastLoss=0.187, valLoss=0.182]\n",
      "Epoch 84/400: 100%|██████████████████████████████████| 56/56 [00:05<00:00, 10.21batch/s, lastLoss=0.189, valLoss=0.184]\n",
      "Epoch 85/400: 100%|██████████████████████████████████| 56/56 [00:05<00:00, 10.28batch/s, lastLoss=0.188, valLoss=0.192]\n",
      "Epoch 86/400: 100%|██████████████████████████████████| 56/56 [00:05<00:00, 10.33batch/s, lastLoss=0.189, valLoss=0.186]\n",
      "Epoch 87/400: 100%|██████████████████████████████████| 56/56 [00:05<00:00, 10.26batch/s, lastLoss=0.188, valLoss=0.185]\n",
      "Epoch 88/400: 100%|██████████████████████████████████| 56/56 [00:05<00:00, 10.29batch/s, lastLoss=0.189, valLoss=0.184]\n",
      "Epoch 89/400: 100%|██████████████████████████████████| 56/56 [00:05<00:00, 10.20batch/s, lastLoss=0.188, valLoss=0.184]\n",
      "Epoch 90/400: 100%|███████████████████████████████████| 56/56 [00:05<00:00, 10.31batch/s, lastLoss=0.187, valLoss=0.19]\n",
      "Epoch 91/400: 100%|██████████████████████████████████| 56/56 [00:05<00:00, 10.34batch/s, lastLoss=0.187, valLoss=0.187]\n",
      "Epoch 92/400: 100%|██████████████████████████████████| 56/56 [00:05<00:00, 10.21batch/s, lastLoss=0.188, valLoss=0.177]\n",
      "Epoch 93/400: 100%|██████████████████████████████████| 56/56 [00:05<00:00, 10.36batch/s, lastLoss=0.188, valLoss=0.185]\n",
      "Epoch 94/400: 100%|██████████████████████████████████| 56/56 [00:05<00:00, 10.18batch/s, lastLoss=0.189, valLoss=0.184]\n",
      "Epoch 95/400: 100%|██████████████████████████████████| 56/56 [00:05<00:00, 10.30batch/s, lastLoss=0.188, valLoss=0.181]\n",
      "Epoch 96/400: 100%|██████████████████████████████████| 56/56 [00:05<00:00, 10.14batch/s, lastLoss=0.187, valLoss=0.183]\n",
      "Epoch 97/400: 100%|██████████████████████████████████| 56/56 [00:05<00:00, 10.36batch/s, lastLoss=0.188, valLoss=0.184]\n",
      "Epoch 98/400: 100%|██████████████████████████████████| 56/56 [00:05<00:00, 10.24batch/s, lastLoss=0.188, valLoss=0.184]\n",
      "Epoch 99/400: 100%|██████████████████████████████████| 56/56 [00:05<00:00, 10.30batch/s, lastLoss=0.188, valLoss=0.187]\n",
      "Epoch 100/400: 100%|█████████████████████████████████| 56/56 [00:05<00:00, 10.21batch/s, lastLoss=0.188, valLoss=0.182]\n",
      "Epoch 101/400: 100%|█████████████████████████████████| 56/56 [00:05<00:00, 10.06batch/s, lastLoss=0.187, valLoss=0.187]\n",
      "Epoch 102/400: 100%|█████████████████████████████████| 56/56 [00:05<00:00, 10.27batch/s, lastLoss=0.188, valLoss=0.187]\n",
      "Epoch 103/400: 100%|█████████████████████████████████| 56/56 [00:05<00:00, 10.24batch/s, lastLoss=0.188, valLoss=0.184]\n",
      "Epoch 104/400: 100%|█████████████████████████████████| 56/56 [00:05<00:00, 10.27batch/s, lastLoss=0.188, valLoss=0.182]\n",
      "Epoch 105/400: 100%|█████████████████████████████████| 56/56 [00:05<00:00, 10.25batch/s, lastLoss=0.187, valLoss=0.185]\n",
      "Epoch 106/400: 100%|█████████████████████████████████| 56/56 [00:05<00:00, 10.14batch/s, lastLoss=0.187, valLoss=0.186]\n",
      "Epoch 107/400: 100%|█████████████████████████████████| 56/56 [00:05<00:00, 10.27batch/s, lastLoss=0.188, valLoss=0.187]\n",
      "Epoch 108/400: 100%|█████████████████████████████████| 56/56 [00:05<00:00,  9.99batch/s, lastLoss=0.188, valLoss=0.178]\n",
      "Epoch 109/400: 100%|█████████████████████████████████| 56/56 [00:06<00:00,  9.08batch/s, lastLoss=0.187, valLoss=0.178]\n",
      "Epoch 110/400: 100%|█████████████████████████████████| 56/56 [00:06<00:00,  9.12batch/s, lastLoss=0.188, valLoss=0.187]\n",
      "Epoch 111/400: 100%|█████████████████████████████████| 56/56 [00:05<00:00, 10.19batch/s, lastLoss=0.187, valLoss=0.182]\n",
      "Epoch 112/400: 100%|█████████████████████████████████| 56/56 [00:05<00:00, 10.24batch/s, lastLoss=0.187, valLoss=0.184]\n",
      "Epoch 113/400: 100%|█████████████████████████████████| 56/56 [00:05<00:00,  9.69batch/s, lastLoss=0.187, valLoss=0.182]\n",
      "Epoch 114/400: 100%|██████████████████████████████████| 56/56 [00:05<00:00, 10.26batch/s, lastLoss=0.189, valLoss=0.19]\n",
      "Epoch 115/400: 100%|█████████████████████████████████| 56/56 [00:06<00:00,  9.11batch/s, lastLoss=0.189, valLoss=0.187]\n",
      "Epoch 116/400: 100%|█████████████████████████████████| 56/56 [00:06<00:00,  8.66batch/s, lastLoss=0.189, valLoss=0.194]\n",
      "Epoch 117/400: 100%|█████████████████████████████████| 56/56 [00:05<00:00,  9.76batch/s, lastLoss=0.189, valLoss=0.186]\n",
      "Epoch 118/400: 100%|█████████████████████████████████| 56/56 [00:06<00:00,  9.06batch/s, lastLoss=0.189, valLoss=0.184]\n",
      "Epoch 119/400: 100%|█████████████████████████████████| 56/56 [00:09<00:00,  5.66batch/s, lastLoss=0.188, valLoss=0.182]\n",
      "Epoch 120/400: 100%|█████████████████████████████████| 56/56 [00:06<00:00,  8.66batch/s, lastLoss=0.187, valLoss=0.181]\n",
      "Epoch 121/400: 100%|█████████████████████████████████| 56/56 [00:05<00:00, 10.32batch/s, lastLoss=0.188, valLoss=0.189]\n",
      "Epoch 122/400: 100%|█████████████████████████████████| 56/56 [00:05<00:00,  9.78batch/s, lastLoss=0.188, valLoss=0.193]\n",
      "Epoch 123/400: 100%|█████████████████████████████████| 56/56 [00:05<00:00, 11.01batch/s, lastLoss=0.188, valLoss=0.179]\n",
      "Epoch 124/400: 100%|██████████████████████████████████| 56/56 [00:05<00:00, 10.88batch/s, lastLoss=0.187, valLoss=0.18]\n",
      "Epoch 125/400: 100%|█████████████████████████████████| 56/56 [00:05<00:00, 10.96batch/s, lastLoss=0.188, valLoss=0.186]\n",
      "Epoch 126/400: 100%|█████████████████████████████████| 56/56 [00:05<00:00, 11.08batch/s, lastLoss=0.188, valLoss=0.184]\n",
      "Epoch 127/400: 100%|█████████████████████████████████| 56/56 [00:05<00:00, 11.01batch/s, lastLoss=0.188, valLoss=0.179]\n",
      "Epoch 128/400: 100%|█████████████████████████████████| 56/56 [00:05<00:00,  9.41batch/s, lastLoss=0.188, valLoss=0.183]\n",
      "Epoch 129/400: 100%|█████████████████████████████████| 56/56 [00:05<00:00, 10.68batch/s, lastLoss=0.187, valLoss=0.183]\n",
      "Epoch 130/400: 100%|█████████████████████████████████| 56/56 [00:06<00:00,  8.23batch/s, lastLoss=0.187, valLoss=0.187]\n",
      "Epoch 131/400: 100%|█████████████████████████████████| 56/56 [00:05<00:00, 10.13batch/s, lastLoss=0.188, valLoss=0.183]\n",
      "Epoch 132/400: 100%|█████████████████████████████████| 56/56 [00:06<00:00,  9.09batch/s, lastLoss=0.187, valLoss=0.187]\n",
      "Epoch 133/400: 100%|█████████████████████████████████| 56/56 [00:05<00:00,  9.68batch/s, lastLoss=0.187, valLoss=0.181]\n",
      "Epoch 134/400: 100%|█████████████████████████████████| 56/56 [00:05<00:00, 10.49batch/s, lastLoss=0.187, valLoss=0.186]\n",
      "Epoch 135/400: 100%|█████████████████████████████████| 56/56 [00:05<00:00, 11.06batch/s, lastLoss=0.187, valLoss=0.184]\n",
      "Epoch 136/400: 100%|█████████████████████████████████| 56/56 [00:05<00:00, 10.32batch/s, lastLoss=0.187, valLoss=0.186]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 137/400: 100%|█████████████████████████████████| 56/56 [00:07<00:00,  7.29batch/s, lastLoss=0.187, valLoss=0.191]\n",
      "Epoch 138/400: 100%|█████████████████████████████████| 56/56 [00:06<00:00,  8.30batch/s, lastLoss=0.187, valLoss=0.187]\n",
      "Epoch 139/400: 100%|█████████████████████████████████| 56/56 [00:06<00:00,  9.09batch/s, lastLoss=0.187, valLoss=0.185]\n",
      "Epoch 140/400: 100%|█████████████████████████████████| 56/56 [00:05<00:00, 10.33batch/s, lastLoss=0.187, valLoss=0.185]\n",
      "Epoch 141/400: 100%|█████████████████████████████████| 56/56 [00:05<00:00,  9.89batch/s, lastLoss=0.188, valLoss=0.181]\n",
      "Epoch 142/400: 100%|█████████████████████████████████| 56/56 [00:06<00:00,  9.28batch/s, lastLoss=0.187, valLoss=0.181]\n",
      "Epoch 143/400: 100%|█████████████████████████████████| 56/56 [00:05<00:00,  9.58batch/s, lastLoss=0.187, valLoss=0.186]\n",
      "Epoch 144/400: 100%|█████████████████████████████████| 56/56 [00:17<00:00,  3.14batch/s, lastLoss=0.187, valLoss=0.182]\n",
      "Epoch 145/400: 100%|█████████████████████████████████| 56/56 [00:26<00:00,  2.08batch/s, lastLoss=0.186, valLoss=0.182]\n",
      "Epoch 146/400: 100%|█████████████████████████████████| 56/56 [00:16<00:00,  3.32batch/s, lastLoss=0.187, valLoss=0.183]\n",
      "Epoch 147/400: 100%|█████████████████████████████████| 56/56 [00:15<00:00,  3.73batch/s, lastLoss=0.187, valLoss=0.182]\n",
      "Epoch 148/400: 100%|█████████████████████████████████| 56/56 [00:15<00:00,  3.72batch/s, lastLoss=0.187, valLoss=0.191]\n",
      "Epoch 149/400: 100%|█████████████████████████████████| 56/56 [00:15<00:00,  3.67batch/s, lastLoss=0.187, valLoss=0.181]\n",
      "Epoch 150/400: 100%|█████████████████████████████████| 56/56 [00:17<00:00,  3.21batch/s, lastLoss=0.187, valLoss=0.188]\n",
      "Epoch 151/400:  30%|██████████                       | 17/56 [00:05<00:22,  1.71batch/s, lastLoss=0.187, valLoss=0.183]"
     ]
    }
   ],
   "source": [
    "train_loss, val_loss =  train(train_loader, rnn, val_loader=test_loader, LR=0.0001, epochs=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "aa42becd",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = LSTM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "31eaa56b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/150: 100%|██████████████████████████████████████████████████████████████████| 56/56 [00:04<00:00, 12.76batch/s]\n",
      "Epoch 2/150: 100%|████████████████████████████████████| 56/56 [00:04<00:00, 12.87batch/s, lastLoss=0.333, valLoss=0.32]\n",
      "Epoch 3/150: 100%|███████████████████████████████████| 56/56 [00:04<00:00, 13.00batch/s, lastLoss=0.282, valLoss=0.251]\n",
      "Epoch 4/150: 100%|███████████████████████████████████| 56/56 [00:04<00:00, 13.05batch/s, lastLoss=0.263, valLoss=0.212]\n",
      "Epoch 5/150: 100%|███████████████████████████████████| 56/56 [00:04<00:00, 13.10batch/s, lastLoss=0.251, valLoss=0.208]\n",
      "Epoch 6/150: 100%|███████████████████████████████████| 56/56 [00:04<00:00, 12.87batch/s, lastLoss=0.242, valLoss=0.209]\n",
      "Epoch 7/150: 100%|███████████████████████████████████| 56/56 [00:04<00:00, 12.88batch/s, lastLoss=0.235, valLoss=0.195]\n",
      "Epoch 8/150: 100%|███████████████████████████████████| 56/56 [00:04<00:00, 11.71batch/s, lastLoss=0.236, valLoss=0.202]\n",
      "Epoch 9/150: 100%|███████████████████████████████████| 56/56 [00:05<00:00, 10.80batch/s, lastLoss=0.229, valLoss=0.197]\n",
      "Epoch 10/150: 100%|██████████████████████████████████| 56/56 [00:04<00:00, 12.29batch/s, lastLoss=0.227, valLoss=0.194]\n",
      "Epoch 11/150: 100%|██████████████████████████████████| 56/56 [00:04<00:00, 11.53batch/s, lastLoss=0.225, valLoss=0.197]\n",
      "Epoch 12/150: 100%|██████████████████████████████████| 56/56 [00:07<00:00,  7.59batch/s, lastLoss=0.222, valLoss=0.201]\n",
      "Epoch 13/150: 100%|███████████████████████████████████| 56/56 [00:06<00:00,  9.17batch/s, lastLoss=0.22, valLoss=0.194]\n",
      "Epoch 14/150: 100%|██████████████████████████████████| 56/56 [00:04<00:00, 12.26batch/s, lastLoss=0.217, valLoss=0.193]\n",
      "Epoch 15/150: 100%|██████████████████████████████████| 56/56 [00:04<00:00, 12.25batch/s, lastLoss=0.216, valLoss=0.195]\n",
      "Epoch 16/150: 100%|██████████████████████████████████| 56/56 [00:04<00:00, 12.65batch/s, lastLoss=0.216, valLoss=0.187]\n",
      "Epoch 17/150: 100%|██████████████████████████████████| 56/56 [00:04<00:00, 12.84batch/s, lastLoss=0.212, valLoss=0.187]\n",
      "Epoch 18/150: 100%|██████████████████████████████████| 56/56 [00:05<00:00, 10.28batch/s, lastLoss=0.211, valLoss=0.185]\n",
      "Epoch 19/150: 100%|██████████████████████████████████| 56/56 [00:04<00:00, 11.41batch/s, lastLoss=0.211, valLoss=0.189]\n",
      "Epoch 20/150: 100%|██████████████████████████████████| 56/56 [00:04<00:00, 12.31batch/s, lastLoss=0.207, valLoss=0.191]\n",
      "Epoch 21/150: 100%|██████████████████████████████████| 56/56 [00:04<00:00, 12.36batch/s, lastLoss=0.209, valLoss=0.187]\n",
      "Epoch 22/150: 100%|██████████████████████████████████| 56/56 [00:04<00:00, 12.16batch/s, lastLoss=0.206, valLoss=0.184]\n",
      "Epoch 23/150:  61%|████████████████████▋             | 34/56 [00:02<00:01, 11.48batch/s, lastLoss=0.206, valLoss=0.192]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [229]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m lstm_train_loss, lstm_val_loss \u001b[38;5;241m=\u001b[39m  \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlstm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mLR\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.0001\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m150\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Documents\\MastersDiss\\Notebooks\\..\\SkinLearning\\Utils\\NN.py:42\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(train_loader, net, LR, epochs, val_loader)\u001b[0m\n\u001b[0;32m     40\u001b[0m current_MSE \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m6\u001b[39m):\n\u001b[1;32m---> 42\u001b[0m     current_MSE\u001b[38;5;241m.\u001b[39mappend(\u001b[43mall_MSE\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredicted\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mitem())\n\u001b[0;32m     43\u001b[0m parameter_loss\u001b[38;5;241m.\u001b[39mappend(current_MSE)\n\u001b[0;32m     44\u001b[0m processed \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\loss.py:101\u001b[0m, in \u001b[0;36mL1Loss.forward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43ml1_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:3261\u001b[0m, in \u001b[0;36ml1_loss\u001b[1;34m(input, target, size_average, reduce, reduction)\u001b[0m\n\u001b[0;32m   3258\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[0;32m   3260\u001b[0m expanded_input, expanded_target \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mbroadcast_tensors(\u001b[38;5;28minput\u001b[39m, target)\n\u001b[1;32m-> 3261\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43ml1_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexpanded_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexpanded_target\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_Reduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_enum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "lstm_train_loss, lstm_val_loss =  train(train_loader, lstm, val_loader=test_loader, LR=0.0001, epochs=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f28a915",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
