{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67ba37dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from torch import tensor\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import random\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "#from numba import jit\n",
    "import pickle\n",
    "from scipy.interpolate import interp1d\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torch\n",
    "from torchsummary import summary\n",
    "import seaborn as sns\n",
    "import sys\n",
    "import torch.nn.functional as F\n",
    "import pywt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from torch.cuda import FloatTensor\n",
    "\n",
    "# Req for package\n",
    "sys.path.append(\"../\")\n",
    "from SkinLearning.Utils.NN import train, test, DEVICE, getParameterLoss, set_seed\n",
    "from SkinLearning.Utils.Dataset import getDataset, getSplit\n",
    "from SkinLearning.Utils.Plotting import plotParameterBars\n",
    "\n",
    "\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "54f387c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "c7b11a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove one FC LAyer\n",
    "class MultiLSTM(nn.Module):\n",
    "    def __init__(self, hidden_size=256, single_fc=True, out=\"f_hidden\"):\n",
    "        super(MultiLSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.out = out\n",
    "        \n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv1d(1, 128, kernel_size=5, padding=1, bias=False),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=2, stride=2),\n",
    "            \n",
    "            nn.Conv1d(128, 256, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=2, stride=2),\n",
    "        \n",
    "            nn.Conv1d(256, 512, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        \n",
    "        self.cnn2 = nn.Sequential(\n",
    "            nn.Conv1d(1, 128, kernel_size=5, padding=1, bias=False),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=2, stride=2),\n",
    "            \n",
    "            nn.Conv1d(128, 256, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=2, stride=2),\n",
    "        \n",
    "            nn.Conv1d(256, 512, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        \n",
    "        self.lstm = nn.LSTM(15, hidden_size, batch_first=True, num_layers=1)\n",
    "    \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256 , 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64), \n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 6),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.shape[0]\n",
    "        x1 = x[:, 0, :].reshape(batch_size, 1, -1)\n",
    "        x2 = x[:, 1, :].reshape(batch_size, 1, -1)\n",
    "        \n",
    "        x1 = self.cnn(x1)\n",
    "        x2 = self.cnn(x2)\n",
    "        \n",
    "        #x = torch.cat([x1, x2], dim=2)\n",
    "\n",
    "        \n",
    "        #h0 = torch.zeros(1, batch_size, 256).to(x.device)\n",
    "        #c0 = torch.zeros((1, batch_size, self.hidden_size)).to(x.device)\n",
    "        o1, (h, c) = self.lstm(x1)\n",
    "        o2, (h2, c) = self.lstm(x2)\n",
    "        \n",
    "        \n",
    "        x = torch.concat([h[-1], h2[-1]], dim=1)\n",
    "        #x = o1\n",
    "        x = x.reshape(batch_size, -1)\n",
    "        x = self.fc(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d16abb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 2241/2241 [00:10<00:00, 216.30it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset, scaler = getDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1e099974",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, test_loader = getSplit(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "dcec4c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = MultiLSTM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "9ff6ce44",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 15/15 [00:00<00:00, 26.04 batch/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(55.27701187133789,\n",
       " array([91.74447  , 14.890617 , 99.20127  , 97.93307  , 23.455414 ,\n",
       "         4.4372635], dtype=float32),\n",
       " 0.35109996994336445)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test(test_loader, lstm, scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "49bb1a35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1500: 100%|█████████████████████████████████████████████████████████████████| 56/56 [00:05<00:00, 10.80batch/s]\n",
      "Epoch 2/1500: 100%|███████████████████████| 56/56 [00:04<00:00, 11.94batch/s, counter=0, lastLoss=0.293, valLoss=0.203]\n",
      "Epoch 3/1500: 100%|███████████████████████| 56/56 [00:04<00:00, 11.27batch/s, counter=0, lastLoss=0.178, valLoss=0.172]\n",
      "Epoch 4/1500: 100%|███████████████████████| 56/56 [00:04<00:00, 11.76batch/s, counter=1, lastLoss=0.165, valLoss=0.181]\n",
      "Epoch 5/1500: 100%|███████████████████████| 56/56 [00:05<00:00, 11.09batch/s, counter=2, lastLoss=0.149, valLoss=0.178]\n",
      "Epoch 6/1500: 100%|███████████████████████| 56/56 [00:04<00:00, 11.55batch/s, counter=3, lastLoss=0.134, valLoss=0.188]\n",
      "Epoch 7/1500: 100%|████████████████████████| 56/56 [00:04<00:00, 11.56batch/s, counter=0, lastLoss=0.124, valLoss=0.16]\n",
      "Epoch 8/1500: 100%|████████████████████████| 56/56 [00:04<00:00, 11.43batch/s, counter=1, lastLoss=0.12, valLoss=0.176]\n",
      "Epoch 9/1500: 100%|███████████████████████| 56/56 [00:04<00:00, 11.53batch/s, counter=2, lastLoss=0.117, valLoss=0.171]\n",
      "Epoch 10/1500: 100%|██████████████████████| 56/56 [00:04<00:00, 11.23batch/s, counter=3, lastLoss=0.112, valLoss=0.192]\n",
      "Epoch 11/1500: 100%|██████████████████████| 56/56 [00:04<00:00, 11.90batch/s, counter=4, lastLoss=0.108, valLoss=0.209]\n",
      "Epoch 12/1500: 100%|██████████████████████| 56/56 [00:05<00:00, 10.99batch/s, counter=5, lastLoss=0.107, valLoss=0.196]\n",
      "Epoch 13/1500: 100%|██████████████████████| 56/56 [00:04<00:00, 12.04batch/s, counter=6, lastLoss=0.105, valLoss=0.199]\n",
      "Epoch 14/1500: 100%|██████████████████████| 56/56 [00:05<00:00, 10.46batch/s, counter=7, lastLoss=0.104, valLoss=0.205]\n",
      "Epoch 15/1500: 100%|██████████████████████| 56/56 [00:04<00:00, 11.81batch/s, counter=8, lastLoss=0.103, valLoss=0.199]\n",
      "Epoch 16/1500: 100%|██████████████████████| 56/56 [00:05<00:00, 11.00batch/s, counter=9, lastLoss=0.101, valLoss=0.194]\n",
      "Epoch 17/1500: 100%|████████████████████| 56/56 [00:04<00:00, 11.65batch/s, counter=10, lastLoss=0.0983, valLoss=0.208]\n",
      "Epoch 18/1500: 100%|█████████████████████| 56/56 [00:05<00:00, 11.11batch/s, counter=11, lastLoss=0.101, valLoss=0.206]\n",
      "Epoch 19/1500: 100%|██████████████████████| 56/56 [00:04<00:00, 11.28batch/s, counter=12, lastLoss=0.101, valLoss=0.21]\n",
      "Epoch 20/1500: 100%|████████████████████| 56/56 [00:04<00:00, 11.30batch/s, counter=13, lastLoss=0.0993, valLoss=0.194]\n",
      "Epoch 21/1500: 100%|████████████████████| 56/56 [00:04<00:00, 11.52batch/s, counter=14, lastLoss=0.0967, valLoss=0.207]\n",
      "Epoch 22/1500: 100%|████████████████████| 56/56 [00:04<00:00, 11.67batch/s, counter=15, lastLoss=0.0966, valLoss=0.198]\n",
      "Epoch 23/1500: 100%|████████████████████| 56/56 [00:05<00:00, 11.13batch/s, counter=16, lastLoss=0.0977, valLoss=0.208]\n",
      "Epoch 24/1500: 100%|████████████████████| 56/56 [00:04<00:00, 11.96batch/s, counter=17, lastLoss=0.0963, valLoss=0.201]\n",
      "Epoch 25/1500: 100%|████████████████████| 56/56 [00:05<00:00, 10.93batch/s, counter=18, lastLoss=0.0965, valLoss=0.207]\n",
      "Epoch 26/1500: 100%|████████████████████| 56/56 [00:04<00:00, 11.97batch/s, counter=19, lastLoss=0.0963, valLoss=0.206]\n",
      "Epoch 27/1500: 100%|████████████████████| 56/56 [00:05<00:00, 10.89batch/s, counter=20, lastLoss=0.0949, valLoss=0.212]\n",
      "Epoch 28/1500: 100%|████████████████████| 56/56 [00:04<00:00, 11.83batch/s, counter=21, lastLoss=0.0949, valLoss=0.209]\n",
      "Epoch 29/1500: 100%|████████████████████| 56/56 [00:05<00:00, 10.74batch/s, counter=22, lastLoss=0.0957, valLoss=0.207]\n",
      "Epoch 30/1500: 100%|████████████████████| 56/56 [00:05<00:00, 10.82batch/s, counter=23, lastLoss=0.0951, valLoss=0.205]\n",
      "Epoch 31/1500: 100%|████████████████████| 56/56 [00:05<00:00, 11.16batch/s, counter=24, lastLoss=0.0948, valLoss=0.211]\n",
      "Epoch 32/1500: 100%|████████████████████| 56/56 [00:04<00:00, 11.50batch/s, counter=25, lastLoss=0.0929, valLoss=0.211]\n",
      "Epoch 33/1500: 100%|████████████████████| 56/56 [00:04<00:00, 11.61batch/s, counter=26, lastLoss=0.0934, valLoss=0.215]\n",
      "Epoch 34/1500: 100%|████████████████████| 56/56 [00:04<00:00, 11.26batch/s, counter=27, lastLoss=0.0943, valLoss=0.217]\n",
      "Epoch 35/1500: 100%|████████████████████| 56/56 [00:04<00:00, 11.85batch/s, counter=28, lastLoss=0.0921, valLoss=0.211]\n",
      "Epoch 36/1500: 100%|████████████████████| 56/56 [00:04<00:00, 11.21batch/s, counter=29, lastLoss=0.0911, valLoss=0.211]\n",
      "Epoch 37/1500: 100%|████████████████████| 56/56 [00:04<00:00, 12.05batch/s, counter=30, lastLoss=0.0911, valLoss=0.214]\n",
      "Epoch 38/1500: 100%|█████████████████████| 56/56 [00:05<00:00, 10.51batch/s, counter=31, lastLoss=0.0917, valLoss=0.21]\n",
      "Epoch 39/1500: 100%|████████████████████| 56/56 [00:04<00:00, 12.06batch/s, counter=32, lastLoss=0.0911, valLoss=0.215]\n",
      "Epoch 40/1500: 100%|████████████████████| 56/56 [00:05<00:00, 10.96batch/s, counter=33, lastLoss=0.0899, valLoss=0.203]\n",
      "Epoch 41/1500: 100%|█████████████████████| 56/56 [00:04<00:00, 11.83batch/s, counter=34, lastLoss=0.0931, valLoss=0.21]\n",
      "Epoch 42/1500: 100%|█████████████████████| 56/56 [00:05<00:00, 10.71batch/s, counter=35, lastLoss=0.091, valLoss=0.215]\n",
      "Epoch 43/1500: 100%|██████████████████████| 56/56 [00:04<00:00, 11.62batch/s, counter=36, lastLoss=0.09, valLoss=0.211]\n",
      "Epoch 44/1500: 100%|████████████████████| 56/56 [00:04<00:00, 11.28batch/s, counter=37, lastLoss=0.0907, valLoss=0.224]\n",
      "Epoch 45/1500: 100%|████████████████████| 56/56 [00:04<00:00, 11.30batch/s, counter=38, lastLoss=0.0893, valLoss=0.202]\n",
      "Epoch 46/1500: 100%|████████████████████| 56/56 [00:05<00:00, 11.13batch/s, counter=39, lastLoss=0.0891, valLoss=0.209]\n",
      "Epoch 47/1500: 100%|████████████████████| 56/56 [00:05<00:00, 11.13batch/s, counter=40, lastLoss=0.0893, valLoss=0.212]\n",
      "Epoch 48/1500: 100%|████████████████████| 56/56 [00:04<00:00, 11.85batch/s, counter=41, lastLoss=0.0886, valLoss=0.217]\n",
      "Epoch 49/1500: 100%|████████████████████| 56/56 [00:04<00:00, 12.17batch/s, counter=42, lastLoss=0.0889, valLoss=0.208]\n",
      "Epoch 50/1500: 100%|█████████████████████| 56/56 [00:04<00:00, 12.68batch/s, counter=43, lastLoss=0.0878, valLoss=0.23]\n",
      "Epoch 51/1500: 100%|████████████████████| 56/56 [00:04<00:00, 12.64batch/s, counter=44, lastLoss=0.0889, valLoss=0.203]\n",
      "Epoch 52/1500: 100%|████████████████████| 56/56 [00:04<00:00, 12.71batch/s, counter=45, lastLoss=0.0894, valLoss=0.227]\n",
      "Epoch 53/1500: 100%|████████████████████| 56/56 [00:04<00:00, 12.62batch/s, counter=46, lastLoss=0.0874, valLoss=0.217]\n",
      "Epoch 54/1500: 100%|████████████████████| 56/56 [00:04<00:00, 12.21batch/s, counter=47, lastLoss=0.0885, valLoss=0.242]\n",
      "Epoch 55/1500: 100%|████████████████████| 56/56 [00:04<00:00, 12.81batch/s, counter=48, lastLoss=0.0918, valLoss=0.223]\n",
      "Epoch 56/1500: 100%|████████████████████| 56/56 [00:04<00:00, 13.36batch/s, counter=49, lastLoss=0.0869, valLoss=0.198]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping after 56 epochs\n",
      "Average train loss: 0.003879894217831038\n",
      "Average validation loss: 0.007644114770823055\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([0.29287187568843365,\n",
       "  0.178091256746224,\n",
       "  0.1651278090264116,\n",
       "  0.14924934227019548,\n",
       "  0.1337069899642042,\n",
       "  0.12390972727111407,\n",
       "  0.12023726864052671,\n",
       "  0.1166123521647283,\n",
       "  0.11219805252871343,\n",
       "  0.10824556874909572,\n",
       "  0.10659497816647802,\n",
       "  0.10467722572918449,\n",
       "  0.10426896025559731,\n",
       "  0.1030503659109984,\n",
       "  0.10063918706561838,\n",
       "  0.09829316407974277,\n",
       "  0.10100247990339994,\n",
       "  0.1005086772409933,\n",
       "  0.09933726569371563,\n",
       "  0.09666824700044734,\n",
       "  0.09662800362067563,\n",
       "  0.09771683399698564,\n",
       "  0.09628901683858462,\n",
       "  0.09646308462002448,\n",
       "  0.09634814877063036,\n",
       "  0.09489081946334668,\n",
       "  0.0949365645647049,\n",
       "  0.09567903713988406,\n",
       "  0.09511102057461228,\n",
       "  0.09477221979094404,\n",
       "  0.09292595939976829,\n",
       "  0.09342557710728475,\n",
       "  0.09426665412528175,\n",
       "  0.09209684641765696,\n",
       "  0.09105379054588932,\n",
       "  0.09108581367347922,\n",
       "  0.09174576361796685,\n",
       "  0.09105341987950462,\n",
       "  0.08993012005729335,\n",
       "  0.09307063317724637,\n",
       "  0.09095588725592409,\n",
       "  0.08996912304844175,\n",
       "  0.09073011483997107,\n",
       "  0.08929956677768912,\n",
       "  0.08910875088934388,\n",
       "  0.08933619356581143,\n",
       "  0.0885514287011964,\n",
       "  0.08886703662574291,\n",
       "  0.0877655755196299,\n",
       "  0.08892362604715995,\n",
       "  0.08941668178886175,\n",
       "  0.08744429251445192,\n",
       "  0.08853988362742322,\n",
       "  0.09182892393852983,\n",
       "  0.08691998557852847,\n",
       "  0.0874041345502649],\n",
       " [0.20316838920116426,\n",
       "  0.1723623141646385,\n",
       "  0.18074042797088624,\n",
       "  0.17844363351662954,\n",
       "  0.1878484586874644,\n",
       "  0.16021994650363922,\n",
       "  0.1755460560321808,\n",
       "  0.17064984738826752,\n",
       "  0.19156557718912762,\n",
       "  0.20906009872754414,\n",
       "  0.19583001534144084,\n",
       "  0.19869507650534313,\n",
       "  0.20507849554220836,\n",
       "  0.19936493535836539,\n",
       "  0.19367989301681518,\n",
       "  0.20777126948038738,\n",
       "  0.20605921347935993,\n",
       "  0.20975182155768077,\n",
       "  0.19417485694090525,\n",
       "  0.20724765757719676,\n",
       "  0.19804695546627044,\n",
       "  0.208323139945666,\n",
       "  0.2009805421034495,\n",
       "  0.20652350187301635,\n",
       "  0.20587125519911448,\n",
       "  0.21196742753187817,\n",
       "  0.2094195117553075,\n",
       "  0.20661395986874898,\n",
       "  0.20525427063306173,\n",
       "  0.21100695927937826,\n",
       "  0.21125980019569396,\n",
       "  0.21464449763298035,\n",
       "  0.2167842944463094,\n",
       "  0.21082184016704558,\n",
       "  0.21093069911003112,\n",
       "  0.21418529351552326,\n",
       "  0.21032158037026724,\n",
       "  0.2147598554690679,\n",
       "  0.20251873930295308,\n",
       "  0.21029681464036307,\n",
       "  0.21497873862584432,\n",
       "  0.2112052728732427,\n",
       "  0.22397873799006143,\n",
       "  0.20157344937324523,\n",
       "  0.2092798501253128,\n",
       "  0.21180392106374105,\n",
       "  0.2165592650572459,\n",
       "  0.208491708834966,\n",
       "  0.22969682415326437,\n",
       "  0.20308046837647756,\n",
       "  0.22738716801007589,\n",
       "  0.2173009326060613,\n",
       "  0.24163407385349273,\n",
       "  0.22278330326080323,\n",
       "  0.1977213849623998,\n",
       "  0.20090813438097635])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train(train_loader, lstm, val_loader=test_loader, LR=0.0001, epochs=1500, early_stopping=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "fe736457",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove one FC LAyer\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self, hidden_size=256, single_fc=True, out=\"f_hidden\"):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.out = out\n",
    "        \n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv1d(1, 128, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=2, stride=2),\n",
    "            \n",
    "            nn.Conv1d(128, 64, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=2, stride=2),\n",
    "        )\n",
    "        \n",
    "        self.cnn2 = nn.Sequential(\n",
    "            nn.Conv1d(1, 128, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=2, stride=2),\n",
    "            \n",
    "            nn.Conv1d(128, 64, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=2, stride=2),\n",
    "        )\n",
    "        \n",
    "        self.lstm = nn.LSTM(15, hidden_size, batch_first=True, num_layers=2)\n",
    "    \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(512, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64 , 6),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.shape[0]\n",
    "        x1 = x[:, 0, :].reshape(batch_size, 1, -1)\n",
    "        x2 = x[:, 1, :].reshape(batch_size, 1, -1)\n",
    "        \n",
    "        x1 = self.cnn(x1)\n",
    "        x2 = self.cnn2(x2)\n",
    "        \n",
    "        #x = torch.cat([x1, x2], dim=2)\n",
    "\n",
    "        \n",
    "        #h0 = torch.zeros(1, batch_size, 256).to(x.device)\n",
    "        #c0 = torch.zeros((1, batch_size, self.hidden_size)).to(x.device)\n",
    "        o1, (h, c) = self.lstm(x1)\n",
    "        o2, (h2, c) = self.lstm(x2)\n",
    "        \n",
    "        \n",
    "        x = torch.concat([h[-1], h2[-1]], dim=1)\n",
    "        x = x.reshape(batch_size, -1)\n",
    "        x = self.fc(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "f1ecf7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ls = LSTM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "9bd15f65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1500:   0%|                                                                          | 0/56 [00:00<?, ?batch/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "input.size(-1) must be equal to input_size. Expected 15, got 32",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[1;32mIn [122]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mls\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mLR\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.0001\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1500\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Documents\\MastersDiss\\Notebooks\\..\\SkinLearning\\Utils\\NN.py:52\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(train_loader, net, LR, epochs, val_loader, early_stopping, patience, optimizer)\u001b[0m\n\u001b[0;32m     49\u001b[0m inp, out \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(DEVICE), data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(DEVICE)\n\u001b[0;32m     51\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 52\u001b[0m predicted \u001b[38;5;241m=\u001b[39m \u001b[43mnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43minp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     54\u001b[0m cost \u001b[38;5;241m=\u001b[39m criterion(out, predicted)\n\u001b[0;32m     55\u001b[0m loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m cost\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Input \u001b[1;32mIn [120]\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     46\u001b[0m x2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcnn2(x2)\n\u001b[0;32m     48\u001b[0m \u001b[38;5;66;03m#x = torch.cat([x1, x2], dim=2)\u001b[39;00m\n\u001b[0;32m     49\u001b[0m \n\u001b[0;32m     50\u001b[0m \n\u001b[0;32m     51\u001b[0m \u001b[38;5;66;03m#h0 = torch.zeros(1, batch_size, 256).to(x.device)\u001b[39;00m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;66;03m#c0 = torch.zeros((1, batch_size, self.hidden_size)).to(x.device)\u001b[39;00m\n\u001b[1;32m---> 53\u001b[0m o1, (h, c) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     54\u001b[0m o2, (h2, c) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlstm(x2)\n\u001b[0;32m     57\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mconcat([h[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], h2[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:772\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m    768\u001b[0m     \u001b[38;5;66;03m# Each batch of the hidden state should match the input sequence that\u001b[39;00m\n\u001b[0;32m    769\u001b[0m     \u001b[38;5;66;03m# the user believes he/she is passing in.\u001b[39;00m\n\u001b[0;32m    770\u001b[0m     hx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpermute_hidden(hx, sorted_indices)\n\u001b[1;32m--> 772\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_forward_args\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_sizes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    773\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_sizes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    774\u001b[0m     result \u001b[38;5;241m=\u001b[39m _VF\u001b[38;5;241m.\u001b[39mlstm(\u001b[38;5;28minput\u001b[39m, hx, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_weights, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers,\n\u001b[0;32m    775\u001b[0m                       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbidirectional, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_first)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:697\u001b[0m, in \u001b[0;36mLSTM.check_forward_args\u001b[1;34m(self, input, hidden, batch_sizes)\u001b[0m\n\u001b[0;32m    692\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcheck_forward_args\u001b[39m(\u001b[38;5;28mself\u001b[39m,  \u001b[38;5;66;03m# type: ignore[override]\u001b[39;00m\n\u001b[0;32m    693\u001b[0m                        \u001b[38;5;28minput\u001b[39m: Tensor,\n\u001b[0;32m    694\u001b[0m                        hidden: Tuple[Tensor, Tensor],\n\u001b[0;32m    695\u001b[0m                        batch_sizes: Optional[Tensor],\n\u001b[0;32m    696\u001b[0m                        ):\n\u001b[1;32m--> 697\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_sizes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    698\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_hidden_size(hidden[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_expected_hidden_size(\u001b[38;5;28minput\u001b[39m, batch_sizes),\n\u001b[0;32m    699\u001b[0m                            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExpected hidden[0] size \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    700\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_hidden_size(hidden[\u001b[38;5;241m1\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_expected_cell_size(\u001b[38;5;28minput\u001b[39m, batch_sizes),\n\u001b[0;32m    701\u001b[0m                            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExpected hidden[1] size \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:210\u001b[0m, in \u001b[0;36mRNNBase.check_input\u001b[1;34m(self, input, batch_sizes)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    207\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput must have \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m dimensions, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    208\u001b[0m             expected_input_dim, \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdim()))\n\u001b[0;32m    209\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_size \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m--> 210\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    211\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput.size(-1) must be equal to input_size. Expected \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    212\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_size, \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)))\n",
      "\u001b[1;31mRuntimeError\u001b[0m: input.size(-1) must be equal to input_size. Expected 15, got 32"
     ]
    }
   ],
   "source": [
    "train(train_loader, ls, val_loader=test_loader, LR=0.0001, epochs=1500, early_stopping=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "6ad4ab97",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 15/15 [00:00<00:00, 15.14 batch/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(92.84402561187744,\n",
       " array([95.01342, 80.83722, 99.74831, 99.70889, 85.74309, 96.01323],\n",
       "       dtype=float32),\n",
       " 0.052071726073821385)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test(test_loader, ls, scaler)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
